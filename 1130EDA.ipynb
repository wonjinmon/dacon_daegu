{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    #pythonhashseed 환경변수 설정\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "light_df = pd.read_csv('./data/external_open/대구 보안등 정보.csv', encoding='cp949')[['설치개수', '소재지지번주소']]\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "#공백으로 구분된 네 개의 비공백 문자열을 찾음\n",
    "\n",
    "light_df[['도시', '구', '동', '번지']] = light_df['소재지지번주소'].str.extract(location_pattern)\n",
    "light_df = light_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "light_df = light_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
    "#도시, 구, 동 열을 기준으로 데이터를 그룹화 함.\n",
    "#sum()을 해주는 이유는 각 데이터의 도시, 구, 동에 대한 보안등의 개수 합\n",
    "light_df.reset_index(inplace=True, drop=True)\n",
    "#reset_index(): 데이터프레임의 인덱스 초기화.\n",
    "#inplace = true는 변경사항을 light_df에 바로 적용(새로운 df가 아닌 기존 df) / drop = true 인덱스 새 열 추가 안함\n",
    "\n",
    "child_area_df = pd.read_csv('./data/external_open/대구 어린이 보호 구역 정보.csv', encoding='cp949')[['소재지지번주소']]\n",
    "#중복된 값이 있으면 값이 겹칠 수 있으니 미리 중복 제거 \n",
    "child_area_df['School Zone'] = 1\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "child_area_df[['도시', '구', '동', '번지']] = child_area_df['소재지지번주소'].str.extract(location_pattern)\n",
    "child_area_df = child_area_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "child_area_df = child_area_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
    "child_area_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "parking_df = pd.read_csv('./data/external_open/대구 주차장 정보.csv', encoding='cp949')[['소재지지번주소', '급지구분']]\n",
    "parking_df = pd.get_dummies(parking_df, columns=['급지구분'])\n",
    "#parking_df값들을 one_hot encoding으로 진행\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "parking_df[['도시', '구', '동', '번지']] = parking_df['소재지지번주소'].str.extract(location_pattern)\n",
    "parking_df = parking_df.drop(columns=['소재지지번주소', '번지'])\n",
    "\n",
    "parking_df = parking_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
    "parking_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>사고일시</th>\n",
       "      <th>요일</th>\n",
       "      <th>기상상태</th>\n",
       "      <th>시군구</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>노면상태</th>\n",
       "      <th>사고유형</th>\n",
       "      <th>사고유형 - 세부분류</th>\n",
       "      <th>법규위반</th>\n",
       "      <th>가해운전자 차종</th>\n",
       "      <th>가해운전자 성별</th>\n",
       "      <th>가해운전자 연령</th>\n",
       "      <th>가해운전자 상해정도</th>\n",
       "      <th>피해운전자 차종</th>\n",
       "      <th>피해운전자 성별</th>\n",
       "      <th>피해운전자 연령</th>\n",
       "      <th>피해운전자 상해정도</th>\n",
       "      <th>사망자수</th>\n",
       "      <th>중상자수</th>\n",
       "      <th>경상자수</th>\n",
       "      <th>부상자수</th>\n",
       "      <th>ECLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCIDENT_00000</td>\n",
       "      <td>2019-01-01 00</td>\n",
       "      <td>화요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 중구 대신동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대사람</td>\n",
       "      <td>길가장자리구역통행중</td>\n",
       "      <td>안전운전불이행</td>\n",
       "      <td>승용</td>\n",
       "      <td>여</td>\n",
       "      <td>51세</td>\n",
       "      <td>상해없음</td>\n",
       "      <td>보행자</td>\n",
       "      <td>여</td>\n",
       "      <td>70세</td>\n",
       "      <td>중상</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCIDENT_00001</td>\n",
       "      <td>2019-01-01 00</td>\n",
       "      <td>화요일</td>\n",
       "      <td>흐림</td>\n",
       "      <td>대구광역시 달서구 감삼동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대사람</td>\n",
       "      <td>보도통행중</td>\n",
       "      <td>기타</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>39세</td>\n",
       "      <td>상해없음</td>\n",
       "      <td>보행자</td>\n",
       "      <td>남</td>\n",
       "      <td>61세</td>\n",
       "      <td>경상</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCIDENT_00002</td>\n",
       "      <td>2019-01-01 01</td>\n",
       "      <td>화요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 수성구 두산동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대사람</td>\n",
       "      <td>차도통행중</td>\n",
       "      <td>안전운전불이행</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>70세</td>\n",
       "      <td>상해없음</td>\n",
       "      <td>보행자</td>\n",
       "      <td>남</td>\n",
       "      <td>38세</td>\n",
       "      <td>경상</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCIDENT_00003</td>\n",
       "      <td>2019-01-01 02</td>\n",
       "      <td>화요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 북구 복현동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대차</td>\n",
       "      <td>추돌</td>\n",
       "      <td>안전운전불이행</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>49세</td>\n",
       "      <td>상해없음</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>36세</td>\n",
       "      <td>중상</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCIDENT_00004</td>\n",
       "      <td>2019-01-01 04</td>\n",
       "      <td>화요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 동구 신암동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대차</td>\n",
       "      <td>추돌</td>\n",
       "      <td>안전운전불이행</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>30세</td>\n",
       "      <td>상해없음</td>\n",
       "      <td>승용</td>\n",
       "      <td>남</td>\n",
       "      <td>52세</td>\n",
       "      <td>경상</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID           사고일시   요일 기상상태            시군구      도로형태 노면상태  \\\n",
       "0  ACCIDENT_00000  2019-01-01 00  화요일   맑음   대구광역시 중구 대신동  단일로 - 기타   건조   \n",
       "1  ACCIDENT_00001  2019-01-01 00  화요일   흐림  대구광역시 달서구 감삼동  단일로 - 기타   건조   \n",
       "2  ACCIDENT_00002  2019-01-01 01  화요일   맑음  대구광역시 수성구 두산동  단일로 - 기타   건조   \n",
       "3  ACCIDENT_00003  2019-01-01 02  화요일   맑음   대구광역시 북구 복현동  단일로 - 기타   건조   \n",
       "4  ACCIDENT_00004  2019-01-01 04  화요일   맑음   대구광역시 동구 신암동  단일로 - 기타   건조   \n",
       "\n",
       "   사고유형 사고유형 - 세부분류     법규위반 가해운전자 차종 가해운전자 성별 가해운전자 연령 가해운전자 상해정도 피해운전자 차종  \\\n",
       "0  차대사람  길가장자리구역통행중  안전운전불이행       승용        여      51세       상해없음      보행자   \n",
       "1  차대사람       보도통행중       기타       승용        남      39세       상해없음      보행자   \n",
       "2  차대사람       차도통행중  안전운전불이행       승용        남      70세       상해없음      보행자   \n",
       "3   차대차          추돌  안전운전불이행       승용        남      49세       상해없음       승용   \n",
       "4   차대차          추돌  안전운전불이행       승용        남      30세       상해없음       승용   \n",
       "\n",
       "  피해운전자 성별 피해운전자 연령 피해운전자 상해정도  사망자수  중상자수  경상자수  부상자수  ECLO  \n",
       "0        여      70세         중상     0     1     0     0     5  \n",
       "1        남      61세         경상     0     0     1     0     3  \n",
       "2        남      38세         경상     0     0     1     0     3  \n",
       "3        남      36세         중상     0     1     0     0     5  \n",
       "4        남      52세         경상     0     0     1     0     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>사고일시</th>\n",
       "      <th>요일</th>\n",
       "      <th>기상상태</th>\n",
       "      <th>시군구</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>노면상태</th>\n",
       "      <th>사고유형</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCIDENT_39609</td>\n",
       "      <td>2022-01-01 01</td>\n",
       "      <td>토요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 수성구 상동</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대사람</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCIDENT_39610</td>\n",
       "      <td>2022-01-01 01</td>\n",
       "      <td>토요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 수성구 지산동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대사람</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCIDENT_39611</td>\n",
       "      <td>2022-01-01 04</td>\n",
       "      <td>토요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 수성구 수성동2가</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCIDENT_39612</td>\n",
       "      <td>2022-01-01 04</td>\n",
       "      <td>토요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 수성구 신매동</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCIDENT_39613</td>\n",
       "      <td>2022-01-01 06</td>\n",
       "      <td>토요일</td>\n",
       "      <td>맑음</td>\n",
       "      <td>대구광역시 달서구 감삼동</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>건조</td>\n",
       "      <td>차대차</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID           사고일시   요일 기상상태              시군구        도로형태 노면상태  \\\n",
       "0  ACCIDENT_39609  2022-01-01 01  토요일   맑음     대구광역시 수성구 상동  교차로 - 교차로안   건조   \n",
       "1  ACCIDENT_39610  2022-01-01 01  토요일   맑음    대구광역시 수성구 지산동    단일로 - 기타   건조   \n",
       "2  ACCIDENT_39611  2022-01-01 04  토요일   맑음  대구광역시 수성구 수성동2가  교차로 - 교차로안   건조   \n",
       "3  ACCIDENT_39612  2022-01-01 04  토요일   맑음    대구광역시 수성구 신매동    단일로 - 기타   건조   \n",
       "4  ACCIDENT_39613  2022-01-01 06  토요일   맑음    대구광역시 달서구 감삼동  교차로 - 교차로안   건조   \n",
       "\n",
       "   사고유형  \n",
       "0  차대사람  \n",
       "1  차대사람  \n",
       "2   차대차  \n",
       "3   차대차  \n",
       "4   차대차  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_org = pd.read_csv(\"./data/train.csv\")\n",
    "test_org = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "countrywide_org = pd.read_csv('./data/external_open/countrywide_accident.csv')\n",
    "countrywide_org = countrywide_org[:100000]\n",
    "display(train_org.head())\n",
    "display(test_org.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_org.copy()\n",
    "test_df = test_org.copy()\n",
    "countrywide_df = countrywide_org.copy()\n",
    "\n",
    "time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})' \n",
    "#날짜와 시간을 추출하기 위한 정규표현식\n",
    "# \\d{4}는 연도(4자리 숫자), \\d{1,2}는 월과 일(1자리 또는 2자리 숫자), 그리고 \\d{1,2}는 시간(1자리 또는 2자리 숫자)\n",
    "\n",
    "train_df[['연', '월', '일', '시간']] = train_org['사고일시'].str.extract(time_pattern)\n",
    "                                                                            #pd.to_numeric함수는 숫자처럼 보이는 문자들을 숫자로 바꿔줌\n",
    "train_df[['연', '월', '일', '시간']] = train_df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화\n",
    "train_df = train_df.drop(columns=['사고일시']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거\n",
    "\n",
    "# 해당 과정을 test_x에 대해서도 반복해줍니다 \n",
    "test_df[['연', '월', '일', '시간']] = test_org['사고일시'].str.extract(time_pattern)\n",
    "test_df[['연', '월', '일', '시간']] = test_df[['연', '월', '일', '시간']].apply(pd.to_numeric)\n",
    "test_df = test_df.drop(columns=['사고일시'])\n",
    "\n",
    "countrywide_df[['연', '월', '일', '시간']] = countrywide_org['사고일시'].str.extract(time_pattern)\n",
    "countrywide_df[['연', '월', '일', '시간']] = countrywide_df[['연', '월', '일', '시간']].apply(pd.to_numeric)\n",
    "countrywide_df = countrywide_df.drop(columns=['사고일시'])\n",
    "\n",
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
    "train_df = train_df.drop(columns=['시군구'])\n",
    "\n",
    "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
    "test_df = test_df.drop(columns=['시군구'])\n",
    "\n",
    "countrywide_df[['도시', '구', '동']] = countrywide_org['시군구'].str.extract(location_pattern)\n",
    "countrywide_df = countrywide_df.drop(columns=['시군구'])\n",
    "\n",
    "\n",
    "road_pattern = r'(.+) - (.+)'\n",
    "\n",
    "train_df[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
    "train_df = train_df.drop(columns=['도로형태'])\n",
    "\n",
    "test_df[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
    "test_df = test_df.drop(columns=['도로형태'])\n",
    "\n",
    "countrywide_df[['도로형태1', '도로형태2']] = countrywide_org['도로형태'].str.extract(road_pattern)\n",
    "countrywide_df = countrywide_df.drop(columns=['도로형태'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39609, 34) (10963, 19) (100000, 34)\n"
     ]
    }
   ],
   "source": [
    "# train_df와 test_df에, light_df와 child_area_df, parking_df를 merge하세요.\n",
    "train_df = pd.merge(train_df, light_df, how='left', on=['도시', '구', '동'])\n",
    "train_df = pd.merge(train_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
    "train_df = pd.merge(train_df, parking_df, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "test_df = pd.merge(test_df, light_df, how='left', on=['도시', '구', '동'])\n",
    "test_df = pd.merge(test_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
    "test_df = pd.merge(test_df, parking_df, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "\n",
    "countrywide_df = pd.merge(countrywide_df, light_df, how='left', on=['도시', '구', '동'])\n",
    "countrywide_df = pd.merge(countrywide_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
    "countrywide_df = pd.merge(countrywide_df, parking_df, how='left', on=['도시', '구', '동'])\n",
    "\n",
    "print(train_df.shape, test_df.shape, countrywide_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', '요일', '기상상태', '노면상태', '사고유형', '사고유형 - 세부분류', '법규위반', '가해운전자 차종',\n",
      "       '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종', '피해운전자 성별',\n",
      "       '피해운전자 연령', '피해운전자 상해정도', '사망자수', '중상자수', '경상자수', '부상자수', 'ECLO', '연',\n",
      "       '월', '일', '시간', '도시', '구', '동', '도로형태1', '도로형태2', '설치개수', 'School Zone',\n",
      "       '급지구분_1', '급지구분_2', '급지구분_3'],\n",
      "      dtype='object')\n",
      "Index(['ID', '요일', '기상상태', '노면상태', '사고유형', '연', '월', '일', '시간', '도시', '구', '동',\n",
      "       '도로형태1', '도로형태2', '설치개수', 'School Zone', '급지구분_1', '급지구분_2', '급지구분_3'],\n",
      "      dtype='object')\n",
      "Index(['ID', '요일', '기상상태', '노면상태', '사고유형', '사고유형 - 세부분류', '법규위반', '가해운전자 차종',\n",
      "       '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종', '피해운전자 성별',\n",
      "       '피해운전자 연령', '피해운전자 상해정도', '사망자수', '중상자수', '경상자수', '부상자수', 'ECLO', '연',\n",
      "       '월', '일', '시간', '도시', '구', '동', '도로형태1', '도로형태2', '설치개수', 'School Zone',\n",
      "       '급지구분_1', '급지구분_2', '급지구분_3'],\n",
      "      dtype='object')\n",
      "(139609, 18) (139609,)\n",
      "Index(['요일', '기상상태', '노면상태', '사고유형', '연', '월', '일', '시간', '도시', '구', '동',\n",
      "       '도로형태1', '도로형태2', '설치개수', 'School Zone', '급지구분_1', '급지구분_2', '급지구분_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df.to_csv(\"./data/train_data_total.csv\", encoding=\"cp949\")\n",
    "test_df.to_csv(\"./data/test_data_total.csv\", encoding=\"cp949\")\n",
    "\n",
    "countrywide_df.to_csv(\"./data/countrywide_data_total.csv\", encoding=\"cp949\")\n",
    "\n",
    "total_df = pd.concat([train_df,countrywide_df])\n",
    "total_df.shape\n",
    "\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)\n",
    "print(countrywide_df.columns)\n",
    "\n",
    "test_x = test_df.drop(columns=['ID']).copy() #column ID열 제거하고 붙여넣기\n",
    "train_x = total_df[test_x.columns].copy() #test.columns 값만 넣기\n",
    "train_y = total_df['ECLO'].copy()\n",
    "\n",
    "# test_x = test_df.drop(columns=['ID']).copy() #column ID열 제거하고 붙여넣기\n",
    "# train_x = train_df[test_x.columns].copy() #test.columns 값만 넣기\n",
    "# train_y = train_df['ECLO'].copy()\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(train_x.columns)\n",
    "# countrywide_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HongWonJin\\Documents\\Dacon_daegu2\\1130EDA.ipynb 셀 7\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HongWonJin/Documents/Dacon_daegu2/1130EDA.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_gu_name \u001b[39m=\u001b[39m ohe\u001b[39m.\u001b[39mfit_transform(train_x[[\u001b[39m\"\u001b[39m\u001b[39m구\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HongWonJin/Documents/Dacon_daegu2/1130EDA.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_gu_name \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(train_gu_name, columns\u001b[39m=\u001b[39m[col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m ohe\u001b[39m.\u001b[39mcategories_[\u001b[39m0\u001b[39m]])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HongWonJin/Documents/Dacon_daegu2/1130EDA.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_x \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([train_x\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m구\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_gu_name], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HongWonJin/Documents/Dacon_daegu2/1130EDA.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m test_gu_name \u001b[39m=\u001b[39m ohe\u001b[39m.\u001b[39mfit_transform(test_x[[\u001b[39m\"\u001b[39m\u001b[39m구\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HongWonJin/Documents/Dacon_daegu2/1130EDA.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m test_gu_name \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(test_gu_name, columns\u001b[39m=\u001b[39m[col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m ohe\u001b[39m.\u001b[39mcategories_[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\HongWonJin\\miniconda3\\envs\\daegu\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[1;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\HongWonJin\\miniconda3\\envs\\daegu\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:676\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    674\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[0;32m    675\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 676\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[0;32m    678\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    680\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    681\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m    682\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\HongWonJin\\miniconda3\\envs\\daegu\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3874\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3871\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3873\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3874\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3876\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   3877\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "\n",
    "# ohe = OneHotEncoder(sparse=False)\n",
    "# train_gu_name = ohe.fit_transform(train_x[[\"구\"]])\n",
    "# train_gu_name = pd.DataFrame(train_gu_name, columns=[col for col in ohe.categories_[0]])\n",
    "# train_x = pd.concat([train_x.drop(columns=['구']), train_gu_name], axis=1)\n",
    "\n",
    "# test_gu_name = ohe.fit_transform(test_x[[\"구\"]])\n",
    "# test_gu_name = pd.DataFrame(test_gu_name, columns=[col for col in ohe.categories_[0]])\n",
    "# test_x = pd.concat([test_x.drop(columns=['구']), test_gu_name], axis=1)\n",
    "\n",
    "# display(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>요일</th>\n",
       "      <th>기상상태</th>\n",
       "      <th>노면상태</th>\n",
       "      <th>사고유형</th>\n",
       "      <th>연</th>\n",
       "      <th>월</th>\n",
       "      <th>일</th>\n",
       "      <th>시간</th>\n",
       "      <th>도시</th>\n",
       "      <th>구</th>\n",
       "      <th>동</th>\n",
       "      <th>도로형태1</th>\n",
       "      <th>도로형태2</th>\n",
       "      <th>설치개수</th>\n",
       "      <th>School Zone</th>\n",
       "      <th>급지구분_1</th>\n",
       "      <th>급지구분_2</th>\n",
       "      <th>급지구분_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.880205</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>4.000367</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.745051</td>\n",
       "      <td>4.246483</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.880205</td>\n",
       "      <td>5.123166</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>4.000367</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.618441</td>\n",
       "      <td>4.738938</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.880205</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>4.000367</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.727300</td>\n",
       "      <td>4.839669</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>473.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.880205</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>5.250542</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.752105</td>\n",
       "      <td>4.208920</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>534.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.880205</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>5.250542</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.881812</td>\n",
       "      <td>4.549091</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         요일      기상상태      노면상태      사고유형     연  월  일  시간        도시         구  \\\n",
       "0  4.880205  4.974292  4.973987  4.000367  2019  1  1   0  4.726704  4.745051   \n",
       "1  4.880205  5.123166  4.973987  4.000367  2019  1  1   0  4.726704  4.618441   \n",
       "2  4.880205  4.974292  4.973987  4.000367  2019  1  1   1  4.726704  4.727300   \n",
       "3  4.880205  4.974292  4.973987  5.250542  2019  1  1   2  4.726704  4.752105   \n",
       "4  4.880205  4.974292  4.973987  5.250542  2019  1  1   4  4.726704  4.881812   \n",
       "\n",
       "          동     도로형태1     도로형태2    설치개수  School Zone  급지구분_1  급지구분_2  급지구분_3  \n",
       "0  4.246483  4.948663  4.852697   391.0          2.0    11.0     0.0     0.0  \n",
       "1  4.738938  4.948663  4.852697   932.0          NaN     0.0     1.0     3.0  \n",
       "2  4.839669  4.948663  4.852697   473.0          5.0     NaN     NaN     NaN  \n",
       "3  4.208920  4.948663  4.852697   534.0         11.0     0.0     9.0     5.0  \n",
       "4  4.549091  4.948663  4.852697  2057.0          NaN     0.0     1.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>요일</th>\n",
       "      <th>기상상태</th>\n",
       "      <th>노면상태</th>\n",
       "      <th>사고유형</th>\n",
       "      <th>연</th>\n",
       "      <th>월</th>\n",
       "      <th>일</th>\n",
       "      <th>시간</th>\n",
       "      <th>도시</th>\n",
       "      <th>구</th>\n",
       "      <th>동</th>\n",
       "      <th>도로형태1</th>\n",
       "      <th>도로형태2</th>\n",
       "      <th>설치개수</th>\n",
       "      <th>School Zone</th>\n",
       "      <th>급지구분_1</th>\n",
       "      <th>급지구분_2</th>\n",
       "      <th>급지구분_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.254352</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>4.000367</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.727300</td>\n",
       "      <td>5.087871</td>\n",
       "      <td>5.092156</td>\n",
       "      <td>5.241587</td>\n",
       "      <td>700.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.254352</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>4.000367</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.727300</td>\n",
       "      <td>4.708819</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.254352</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>5.250542</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.727300</td>\n",
       "      <td>4.945578</td>\n",
       "      <td>5.092156</td>\n",
       "      <td>5.241587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.254352</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>5.250542</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.727300</td>\n",
       "      <td>4.438172</td>\n",
       "      <td>4.948663</td>\n",
       "      <td>4.852697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.254352</td>\n",
       "      <td>4.974292</td>\n",
       "      <td>4.973987</td>\n",
       "      <td>5.250542</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.726704</td>\n",
       "      <td>4.618441</td>\n",
       "      <td>4.738938</td>\n",
       "      <td>5.092156</td>\n",
       "      <td>5.241587</td>\n",
       "      <td>932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         요일      기상상태      노면상태      사고유형     연  월  일  시간        도시         구  \\\n",
       "0  5.254352  4.974292  4.973987  4.000367  2022  1  1   1  4.726704  4.727300   \n",
       "1  5.254352  4.974292  4.973987  4.000367  2022  1  1   1  4.726704  4.727300   \n",
       "2  5.254352  4.974292  4.973987  5.250542  2022  1  1   4  4.726704  4.727300   \n",
       "3  5.254352  4.974292  4.973987  5.250542  2022  1  1   4  4.726704  4.727300   \n",
       "4  5.254352  4.974292  4.973987  5.250542  2022  1  1   6  4.726704  4.618441   \n",
       "\n",
       "          동     도로형태1     도로형태2   설치개수  School Zone  급지구분_1  급지구분_2  급지구분_3  \n",
       "0  5.087871  5.092156  5.241587  700.0          5.0     NaN     NaN     NaN  \n",
       "1  4.708819  4.948663  4.852697    NaN         10.0     0.0     0.0     2.0  \n",
       "2  4.945578  5.092156  5.241587    NaN          1.0     NaN     NaN     NaN  \n",
       "3  4.438172  4.948663  4.852697    NaN          7.0     0.0     2.0     1.0  \n",
       "4  4.738938  5.092156  5.241587  932.0          NaN     0.0     1.0     3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index) #object값 list에 넣음\n",
    "# 추출된 문자열 변수 확인\n",
    "display(categorical_features) #object값 출력\n",
    "\n",
    "for i in categorical_features: #인코딩 적용한 값 반환\n",
    "    le = TargetEncoder(cols=[i])\n",
    "    train_x[i] = le.fit_transform(train_x[i], train_y)\n",
    "    test_x[i] = le.transform(test_x[i])\n",
    "#target encdoer 주의사항: train은 fit_transform인 반면, test는 transform만 진행!\n",
    "\n",
    "    \n",
    "display(train_x.head())\n",
    "display(test_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.fillna(0, inplace=True)\n",
    "# test_x.fillna(0, inplace=True)\n",
    "\n",
    "train_x['설치개수'] = train_x['설치개수'].fillna(train_x['설치개수'].mean())\n",
    "train_x['School Zone'] = train_x['School Zone'].fillna(train_x['School Zone'].mean())\n",
    "\n",
    "train_x['급지구분_1'] = train_x['급지구분_1'].fillna(train_x['급지구분_1'].mean())\n",
    "train_x['급지구분_2'] = train_x['급지구분_2'].fillna(train_x['급지구분_2'].mean())\n",
    "train_x['급지구분_3'] = train_x['급지구분_3'].fillna(train_x['급지구분_3'].mean())\n",
    "\n",
    "\n",
    "test_x['설치개수'] = test_x['설치개수'].fillna(test_x['설치개수'].mean())\n",
    "test_x['School Zone'] = test_x['School Zone'].fillna(test_x['School Zone'].mean())\n",
    "\n",
    "test_x['급지구분_1'] = test_x['급지구분_1'].fillna(test_x['급지구분_1'].mean())\n",
    "test_x['급지구분_2'] = test_x['급지구분_2'].fillna(test_x['급지구분_2'].mean())\n",
    "test_x['급지구분_3'] = test_x['급지구분_3'].fillna(test_x['급지구분_3'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l1 as l1_regularizer, l2 as l2_regularizer\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    # y_true = tf.cast(y_true, tf.float32)\n",
    "    # y_pred = tf.cast(y_pred, tf.float32)\n",
    "    # squared_error = tf.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))\n",
    "    # return tf.sqrt(tf.reduce_mean(squared_error))\n",
    "    \n",
    "    y_true = tf.maximum(tf.cast(y_true, tf.float32), 0)\n",
    "    y_pred = tf.maximum(tf.cast(y_pred, tf.float32), 0)\n",
    "    squared_error = tf.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))\n",
    "    \n",
    "    return tf.sqrt(tf.reduce_mean(squared_error))\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return rmsle(y_true, y_pred)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return rmsle(y_true, y_pred)\n",
    "\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=35, verbose=2, mode='min', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=4, min_lr=0.00001),\n",
    "    tf.keras.callbacks.TerminateOnNaN()\n",
    "] \n",
    "\n",
    "def create_model(l1_reg, l2_reg, learning_rate):\n",
    "    input_layer = tf.keras.Input(shape=(len(train_x.columns),))\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=0.00001)(input_layer)\n",
    "    x = tf.keras.layers.Dense(24, kernel_regularizer=l1_regularizer(l1_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=0.00001)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(48, kernel_regularizer=l2_regularizer(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=0.00001)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # x = tf.keras.layers.Dense(96, kernel_regularizer=l2_regularizer(l2_reg))(x)\n",
    "    # x = tf.keras.layers.BatchNormalization(epsilon=0.00001)(x)\n",
    "    # x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss=loss_fn,\n",
    "                  metrics=[metric_fn])\n",
    "    return model\n",
    "\n",
    "best_params = {'batch_size': 128, 'l1_reg': 0.0001, 'l2_reg': 0.0001, 'learning_rate': 0.005}\n",
    "optimized_model = create_model(best_params['l1_reg'], best_params['l2_reg'], best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------0-------------------------\n",
      "Epoch 1/177\n",
      "873/873 [==============================] - 4s 3ms/step - loss: 0.4747 - metric_fn: 0.4648 - val_loss: 0.4566 - val_metric_fn: 0.4485 - lr: 0.0050\n",
      "Epoch 2/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4538 - metric_fn: 0.4475 - val_loss: 0.4551 - val_metric_fn: 0.4499 - lr: 0.0050\n",
      "Epoch 3/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4511 - metric_fn: 0.4468 - val_loss: 0.4509 - val_metric_fn: 0.4472 - lr: 0.0050\n",
      "Epoch 4/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4495 - metric_fn: 0.4463 - val_loss: 0.4501 - val_metric_fn: 0.4471 - lr: 0.0050\n",
      "Epoch 5/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4487 - metric_fn: 0.4461 - val_loss: 0.4506 - val_metric_fn: 0.4481 - lr: 0.0050\n",
      "Epoch 6/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4483 - metric_fn: 0.4462 - val_loss: 0.4500 - val_metric_fn: 0.4478 - lr: 0.0050\n",
      "Epoch 7/177\n",
      "873/873 [==============================] - 2s 2ms/step - loss: 0.4476 - metric_fn: 0.4457 - val_loss: 0.4489 - val_metric_fn: 0.4470 - lr: 0.0050\n",
      "Epoch 8/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4475 - metric_fn: 0.4459 - val_loss: 0.4484 - val_metric_fn: 0.4468 - lr: 0.0050\n",
      "Epoch 9/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4471 - metric_fn: 0.4457 - val_loss: 0.4482 - val_metric_fn: 0.4467 - lr: 0.0050\n",
      "Epoch 10/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4457 - val_loss: 0.4491 - val_metric_fn: 0.4478 - lr: 0.0050\n",
      "Epoch 11/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4456 - val_loss: 0.4475 - val_metric_fn: 0.4462 - lr: 0.0050\n",
      "Epoch 12/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4467 - metric_fn: 0.4457 - val_loss: 0.4484 - val_metric_fn: 0.4474 - lr: 0.0050\n",
      "Epoch 13/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4489 - val_metric_fn: 0.4478 - lr: 0.0050\n",
      "Epoch 14/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4456 - val_loss: 0.4472 - val_metric_fn: 0.4462 - lr: 0.0050\n",
      "Epoch 15/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4454 - val_loss: 0.4475 - val_metric_fn: 0.4465 - lr: 0.0050\n",
      "Epoch 16/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4453 - val_loss: 0.4481 - val_metric_fn: 0.4471 - lr: 0.0050\n",
      "Epoch 17/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4455 - val_loss: 0.4478 - val_metric_fn: 0.4469 - lr: 0.0050\n",
      "Epoch 18/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4455 - val_loss: 0.4479 - val_metric_fn: 0.4470 - lr: 0.0050\n",
      "Epoch 19/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4450 - val_loss: 0.4471 - val_metric_fn: 0.4463 - lr: 0.0035\n",
      "Epoch 20/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4451 - val_loss: 0.4471 - val_metric_fn: 0.4463 - lr: 0.0035\n",
      "Epoch 21/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4452 - val_loss: 0.4477 - val_metric_fn: 0.4468 - lr: 0.0035\n",
      "Epoch 22/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4452 - val_loss: 0.4473 - val_metric_fn: 0.4465 - lr: 0.0035\n",
      "Epoch 23/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4449 - val_loss: 0.4471 - val_metric_fn: 0.4464 - lr: 0.0025\n",
      "Epoch 24/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4450 - val_loss: 0.4468 - val_metric_fn: 0.4460 - lr: 0.0025\n",
      "Epoch 25/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4448 - val_loss: 0.4473 - val_metric_fn: 0.4466 - lr: 0.0025\n",
      "Epoch 26/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4451 - val_loss: 0.4479 - val_metric_fn: 0.4472 - lr: 0.0025\n",
      "Epoch 27/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4451 - val_loss: 0.4468 - val_metric_fn: 0.4460 - lr: 0.0025\n",
      "Epoch 28/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4449 - val_loss: 0.4468 - val_metric_fn: 0.4460 - lr: 0.0025\n",
      "Epoch 29/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4449 - val_loss: 0.4472 - val_metric_fn: 0.4465 - lr: 0.0017\n",
      "Epoch 30/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4450 - val_loss: 0.4468 - val_metric_fn: 0.4461 - lr: 0.0017\n",
      "Epoch 31/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4448 - val_loss: 0.4466 - val_metric_fn: 0.4459 - lr: 0.0017\n",
      "Epoch 32/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4449 - val_loss: 0.4470 - val_metric_fn: 0.4463 - lr: 0.0017\n",
      "Epoch 33/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4448 - val_loss: 0.4469 - val_metric_fn: 0.4463 - lr: 0.0017\n",
      "Epoch 34/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4449 - val_loss: 0.4473 - val_metric_fn: 0.4466 - lr: 0.0017\n",
      "Epoch 35/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4468 - val_metric_fn: 0.4461 - lr: 0.0017\n",
      "Epoch 36/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4447 - val_loss: 0.4467 - val_metric_fn: 0.4460 - lr: 0.0012\n",
      "Epoch 37/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4465 - val_metric_fn: 0.4459 - lr: 0.0012\n",
      "Epoch 38/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4468 - val_metric_fn: 0.4462 - lr: 0.0012\n",
      "Epoch 39/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4467 - val_metric_fn: 0.4461 - lr: 0.0012\n",
      "Epoch 40/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4464 - val_metric_fn: 0.4458 - lr: 8.4035e-04\n",
      "Epoch 41/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4467 - val_metric_fn: 0.4461 - lr: 8.4035e-04\n",
      "Epoch 42/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4465 - val_metric_fn: 0.4459 - lr: 8.4035e-04\n",
      "Epoch 43/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4444 - val_loss: 0.4465 - val_metric_fn: 0.4459 - lr: 8.4035e-04\n",
      "Epoch 44/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4466 - val_metric_fn: 0.4460 - lr: 8.4035e-04\n",
      "Epoch 45/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 5.8825e-04\n",
      "Epoch 46/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4465 - val_metric_fn: 0.4459 - lr: 5.8825e-04\n",
      "Epoch 47/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4445 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 5.8825e-04\n",
      "Epoch 48/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4445 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 5.8825e-04\n",
      "Epoch 49/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 4.1177e-04\n",
      "Epoch 50/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4444 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 4.1177e-04\n",
      "Epoch 51/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4446 - val_loss: 0.4463 - val_metric_fn: 0.4458 - lr: 4.1177e-04\n",
      "Epoch 52/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4445 - val_loss: 0.4464 - val_metric_fn: 0.4459 - lr: 4.1177e-04\n",
      "Epoch 53/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4444 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.8824e-04\n",
      "Epoch 54/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4445 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.8824e-04\n",
      "Epoch 55/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4446 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.8824e-04\n",
      "Epoch 56/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4445 - val_loss: 0.4462 - val_metric_fn: 0.4458 - lr: 2.8824e-04\n",
      "Epoch 57/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4445 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 2.8824e-04\n",
      "Epoch 58/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4444 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.0177e-04\n",
      "Epoch 59/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.0177e-04\n",
      "Epoch 60/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.0177e-04\n",
      "Epoch 61/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4444 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 2.0177e-04\n",
      "Epoch 62/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 63/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4446 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 64/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 65/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4444 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 66/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 67/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 68/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4462 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 69/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.4124e-04\n",
      "Epoch 70/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 9.8866e-05\n",
      "Epoch 71/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 9.8866e-05\n",
      "Epoch 72/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4444 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 9.8866e-05\n",
      "Epoch 73/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4445 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 9.8866e-05\n",
      "Epoch 74/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 6.9206e-05\n",
      "Epoch 75/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 6.9206e-05\n",
      "Epoch 76/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4444 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 6.9206e-05\n",
      "Epoch 77/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 6.9206e-05\n",
      "Epoch 78/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4456 - lr: 4.8445e-05\n",
      "Epoch 79/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 4.8445e-05\n",
      "Epoch 80/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4456 - lr: 4.8445e-05\n",
      "Epoch 81/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 4.8445e-05\n",
      "Epoch 82/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 3.3911e-05\n",
      "Epoch 83/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 3.3911e-05\n",
      "Epoch 84/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4444 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 3.3911e-05\n",
      "Epoch 85/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4456 - lr: 3.3911e-05\n",
      "Epoch 86/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 2.3738e-05\n",
      "Epoch 87/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 2.3738e-05\n",
      "Epoch 88/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 2.3738e-05\n",
      "Epoch 89/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 2.3738e-05\n",
      "Epoch 90/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.6616e-05\n",
      "Epoch 91/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4456 - lr: 1.6616e-05\n",
      "Epoch 92/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.6616e-05\n",
      "Epoch 93/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.6616e-05\n",
      "Epoch 94/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4456 - lr: 1.1632e-05\n",
      "Epoch 95/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.1632e-05\n",
      "Epoch 96/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.1632e-05\n",
      "Epoch 97/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.1632e-05\n",
      "Epoch 98/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 99/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 100/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 101/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 102/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 103/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 104/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 105/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 106/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 107/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 108/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 109/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 110/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4443 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 111/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 112/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 113/177\n",
      "862/873 [============================>.] - ETA: 0s - loss: 0.4447 - metric_fn: 0.4444Restoring model weights from the end of the best epoch: 78.\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4444 - val_loss: 0.4461 - val_metric_fn: 0.4457 - lr: 1.0000e-05\n",
      "Epoch 113: early stopping\n",
      "343/343 [==============================] - 1s 1ms/step\n",
      "-------------------1-------------------------\n",
      "Epoch 1/177\n",
      "873/873 [==============================] - 4s 3ms/step - loss: 0.4911 - metric_fn: 0.4812 - val_loss: 0.4526 - val_metric_fn: 0.4455 - lr: 0.0050\n",
      "Epoch 2/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4547 - metric_fn: 0.4487 - val_loss: 0.4493 - val_metric_fn: 0.4451 - lr: 0.0050\n",
      "Epoch 3/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4516 - metric_fn: 0.4476 - val_loss: 0.4459 - val_metric_fn: 0.4431 - lr: 0.0050\n",
      "Epoch 4/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4501 - metric_fn: 0.4472 - val_loss: 0.4455 - val_metric_fn: 0.4435 - lr: 0.0050\n",
      "Epoch 5/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4494 - metric_fn: 0.4470 - val_loss: 0.4449 - val_metric_fn: 0.4434 - lr: 0.0050\n",
      "Epoch 6/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4488 - metric_fn: 0.4469 - val_loss: 0.4454 - val_metric_fn: 0.4442 - lr: 0.0050\n",
      "Epoch 7/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4484 - metric_fn: 0.4468 - val_loss: 0.4441 - val_metric_fn: 0.4431 - lr: 0.0050\n",
      "Epoch 8/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4482 - metric_fn: 0.4468 - val_loss: 0.4446 - val_metric_fn: 0.4439 - lr: 0.0050\n",
      "Epoch 9/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4478 - metric_fn: 0.4466 - val_loss: 0.4460 - val_metric_fn: 0.4456 - lr: 0.0050\n",
      "Epoch 10/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4474 - metric_fn: 0.4464 - val_loss: 0.4449 - val_metric_fn: 0.4444 - lr: 0.0050\n",
      "Epoch 11/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4476 - metric_fn: 0.4465 - val_loss: 0.4450 - val_metric_fn: 0.4445 - lr: 0.0050\n",
      "Epoch 12/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4461 - val_loss: 0.4437 - val_metric_fn: 0.4433 - lr: 0.0035\n",
      "Epoch 13/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4462 - val_loss: 0.4441 - val_metric_fn: 0.4437 - lr: 0.0035\n",
      "Epoch 14/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4471 - metric_fn: 0.4463 - val_loss: 0.4459 - val_metric_fn: 0.4457 - lr: 0.0035\n",
      "Epoch 15/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4461 - val_loss: 0.4434 - val_metric_fn: 0.4432 - lr: 0.0035\n",
      "Epoch 16/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4461 - val_loss: 0.4436 - val_metric_fn: 0.4433 - lr: 0.0035\n",
      "Epoch 17/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4467 - metric_fn: 0.4459 - val_loss: 0.4435 - val_metric_fn: 0.4433 - lr: 0.0035\n",
      "Epoch 18/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4461 - val_loss: 0.4433 - val_metric_fn: 0.4431 - lr: 0.0035\n",
      "Epoch 19/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4461 - val_loss: 0.4441 - val_metric_fn: 0.4438 - lr: 0.0035\n",
      "Epoch 20/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4461 - val_loss: 0.4434 - val_metric_fn: 0.4432 - lr: 0.0035\n",
      "Epoch 21/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4461 - val_loss: 0.4437 - val_metric_fn: 0.4435 - lr: 0.0035\n",
      "Epoch 22/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4461 - val_loss: 0.4439 - val_metric_fn: 0.4437 - lr: 0.0035\n",
      "Epoch 23/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4466 - metric_fn: 0.4459 - val_loss: 0.4440 - val_metric_fn: 0.4437 - lr: 0.0025\n",
      "Epoch 24/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4466 - metric_fn: 0.4459 - val_loss: 0.4437 - val_metric_fn: 0.4436 - lr: 0.0025\n",
      "Epoch 25/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4466 - metric_fn: 0.4459 - val_loss: 0.4437 - val_metric_fn: 0.4435 - lr: 0.0025\n",
      "Epoch 26/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4458 - val_loss: 0.4431 - val_metric_fn: 0.4429 - lr: 0.0025\n",
      "Epoch 27/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4457 - val_loss: 0.4431 - val_metric_fn: 0.4430 - lr: 0.0025\n",
      "Epoch 28/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4465 - metric_fn: 0.4459 - val_loss: 0.4433 - val_metric_fn: 0.4432 - lr: 0.0025\n",
      "Epoch 29/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4466 - metric_fn: 0.4459 - val_loss: 0.4435 - val_metric_fn: 0.4434 - lr: 0.0025\n",
      "Epoch 30/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4465 - metric_fn: 0.4458 - val_loss: 0.4431 - val_metric_fn: 0.4429 - lr: 0.0025\n",
      "Epoch 31/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4456 - val_loss: 0.4429 - val_metric_fn: 0.4428 - lr: 0.0017\n",
      "Epoch 32/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4456 - val_loss: 0.4433 - val_metric_fn: 0.4431 - lr: 0.0017\n",
      "Epoch 33/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4456 - val_loss: 0.4431 - val_metric_fn: 0.4429 - lr: 0.0017\n",
      "Epoch 34/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4456 - val_loss: 0.4434 - val_metric_fn: 0.4433 - lr: 0.0017\n",
      "Epoch 35/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4457 - val_loss: 0.4432 - val_metric_fn: 0.4430 - lr: 0.0017\n",
      "Epoch 36/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4456 - val_loss: 0.4430 - val_metric_fn: 0.4430 - lr: 0.0012\n",
      "Epoch 37/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4455 - val_loss: 0.4434 - val_metric_fn: 0.4433 - lr: 0.0012\n",
      "Epoch 38/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4455 - val_loss: 0.4433 - val_metric_fn: 0.4433 - lr: 0.0012\n",
      "Epoch 39/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4455 - val_loss: 0.4434 - val_metric_fn: 0.4433 - lr: 0.0012\n",
      "Epoch 40/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4454 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 8.4035e-04\n",
      "Epoch 41/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4455 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 8.4035e-04\n",
      "Epoch 42/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 8.4035e-04\n",
      "Epoch 43/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4454 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 8.4035e-04\n",
      "Epoch 44/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4454 - val_loss: 0.4431 - val_metric_fn: 0.4431 - lr: 8.4035e-04\n",
      "Epoch 45/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4454 - val_loss: 0.4430 - val_metric_fn: 0.4430 - lr: 5.8825e-04\n",
      "Epoch 46/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 5.8825e-04\n",
      "Epoch 47/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 5.8825e-04\n",
      "Epoch 48/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4454 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 5.8825e-04\n",
      "Epoch 49/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4429 - val_metric_fn: 0.4429 - lr: 4.1177e-04\n",
      "Epoch 50/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 4.1177e-04\n",
      "Epoch 51/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 4.1177e-04\n",
      "Epoch 52/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 4.1177e-04\n",
      "Epoch 53/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4429 - lr: 2.8824e-04\n",
      "Epoch 54/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4428 - val_metric_fn: 0.4429 - lr: 2.8824e-04\n",
      "Epoch 55/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 2.8824e-04\n",
      "Epoch 56/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4453 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.8824e-04\n",
      "Epoch 57/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 2.0177e-04\n",
      "Epoch 58/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4428 - val_metric_fn: 0.4428 - lr: 2.0177e-04\n",
      "Epoch 59/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.0177e-04\n",
      "Epoch 60/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4428 - val_metric_fn: 0.4429 - lr: 2.0177e-04\n",
      "Epoch 61/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 62/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 63/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 64/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 65/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 66/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 67/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 68/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.4124e-04\n",
      "Epoch 69/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 9.8866e-05\n",
      "Epoch 70/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 9.8866e-05\n",
      "Epoch 71/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 9.8866e-05\n",
      "Epoch 72/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 9.8866e-05\n",
      "Epoch 73/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 6.9206e-05\n",
      "Epoch 74/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 6.9206e-05\n",
      "Epoch 75/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4426 - val_metric_fn: 0.4428 - lr: 6.9206e-05\n",
      "Epoch 76/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 6.9206e-05\n",
      "Epoch 77/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 4.8445e-05\n",
      "Epoch 78/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 4.8445e-05\n",
      "Epoch 79/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 4.8445e-05\n",
      "Epoch 80/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 4.8445e-05\n",
      "Epoch 81/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 3.3911e-05\n",
      "Epoch 82/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 3.3911e-05\n",
      "Epoch 83/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 3.3911e-05\n",
      "Epoch 84/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 3.3911e-05\n",
      "Epoch 85/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.3738e-05\n",
      "Epoch 86/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.3738e-05\n",
      "Epoch 87/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.3738e-05\n",
      "Epoch 88/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 2.3738e-05\n",
      "Epoch 89/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4426 - val_metric_fn: 0.4428 - lr: 1.6616e-05\n",
      "Epoch 90/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.6616e-05\n",
      "Epoch 91/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.6616e-05\n",
      "Epoch 92/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.6616e-05\n",
      "Epoch 93/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.1632e-05\n",
      "Epoch 94/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.1632e-05\n",
      "Epoch 95/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.1632e-05\n",
      "Epoch 96/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.1632e-05\n",
      "Epoch 97/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 98/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4426 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 99/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 100/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 101/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 102/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 103/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 104/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 105/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 106/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 107/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 108/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 109/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 110/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 111/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 112/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 113/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 114/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 115/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 116/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 117/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 118/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 119/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 120/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 121/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 122/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 123/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 124/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 125/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 126/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 127/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 128/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 129/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 130/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 131/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4451 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 132/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 133/177\n",
      "868/873 [============================>.] - ETA: 0s - loss: 0.4453 - metric_fn: 0.4450Restoring model weights from the end of the best epoch: 98.\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4427 - val_metric_fn: 0.4428 - lr: 1.0000e-05\n",
      "Epoch 133: early stopping\n",
      "343/343 [==============================] - 1s 1ms/step\n",
      "-------------------2-------------------------\n",
      "Epoch 1/177\n",
      "873/873 [==============================] - 5s 3ms/step - loss: 0.4834 - metric_fn: 0.4729 - val_loss: 0.4606 - val_metric_fn: 0.4526 - lr: 0.0050\n",
      "Epoch 2/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4531 - metric_fn: 0.4467 - val_loss: 0.4553 - val_metric_fn: 0.4505 - lr: 0.0050\n",
      "Epoch 3/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4503 - metric_fn: 0.4463 - val_loss: 0.4531 - val_metric_fn: 0.4500 - lr: 0.0050\n",
      "Epoch 4/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4484 - metric_fn: 0.4456 - val_loss: 0.4516 - val_metric_fn: 0.4492 - lr: 0.0050\n",
      "Epoch 5/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4480 - metric_fn: 0.4457 - val_loss: 0.4510 - val_metric_fn: 0.4489 - lr: 0.0050\n",
      "Epoch 6/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4473 - metric_fn: 0.4453 - val_loss: 0.4538 - val_metric_fn: 0.4522 - lr: 0.0050\n",
      "Epoch 7/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4452 - val_loss: 0.4500 - val_metric_fn: 0.4489 - lr: 0.0050\n",
      "Epoch 8/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4451 - val_loss: 0.4511 - val_metric_fn: 0.4500 - lr: 0.0050\n",
      "Epoch 9/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4451 - val_loss: 0.4505 - val_metric_fn: 0.4497 - lr: 0.0050\n",
      "Epoch 10/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4451 - val_loss: 0.4497 - val_metric_fn: 0.4489 - lr: 0.0050\n",
      "Epoch 11/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4452 - val_loss: 0.4508 - val_metric_fn: 0.4500 - lr: 0.0050\n",
      "Epoch 12/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4451 - val_loss: 0.4511 - val_metric_fn: 0.4504 - lr: 0.0050\n",
      "Epoch 13/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4450 - val_loss: 0.4494 - val_metric_fn: 0.4487 - lr: 0.0050\n",
      "Epoch 14/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4450 - val_loss: 0.4494 - val_metric_fn: 0.4488 - lr: 0.0050\n",
      "Epoch 15/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4448 - val_loss: 0.4498 - val_metric_fn: 0.4492 - lr: 0.0050\n",
      "Epoch 16/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4448 - val_loss: 0.4507 - val_metric_fn: 0.4502 - lr: 0.0050\n",
      "Epoch 17/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4448 - val_loss: 0.4521 - val_metric_fn: 0.4514 - lr: 0.0050\n",
      "Epoch 18/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4448 - val_loss: 0.4494 - val_metric_fn: 0.4488 - lr: 0.0035\n",
      "Epoch 19/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4446 - val_loss: 0.4489 - val_metric_fn: 0.4484 - lr: 0.0035\n",
      "Epoch 20/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4446 - val_loss: 0.4490 - val_metric_fn: 0.4486 - lr: 0.0035\n",
      "Epoch 21/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4446 - val_loss: 0.4489 - val_metric_fn: 0.4484 - lr: 0.0035\n",
      "Epoch 22/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4444 - val_loss: 0.4488 - val_metric_fn: 0.4484 - lr: 0.0035\n",
      "Epoch 23/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4446 - val_loss: 0.4494 - val_metric_fn: 0.4490 - lr: 0.0035\n",
      "Epoch 24/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4444 - val_loss: 0.4486 - val_metric_fn: 0.4481 - lr: 0.0025\n",
      "Epoch 25/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4445 - val_loss: 0.4490 - val_metric_fn: 0.4486 - lr: 0.0025\n",
      "Epoch 26/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4443 - val_loss: 0.4485 - val_metric_fn: 0.4482 - lr: 0.0025\n",
      "Epoch 27/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4444 - val_loss: 0.4486 - val_metric_fn: 0.4482 - lr: 0.0025\n",
      "Epoch 28/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4493 - val_metric_fn: 0.4490 - lr: 0.0025\n",
      "Epoch 29/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4482 - val_metric_fn: 0.4478 - lr: 0.0017\n",
      "Epoch 30/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4441 - val_loss: 0.4482 - val_metric_fn: 0.4479 - lr: 0.0017\n",
      "Epoch 31/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4442 - val_loss: 0.4484 - val_metric_fn: 0.4481 - lr: 0.0017\n",
      "Epoch 32/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4440 - val_loss: 0.4485 - val_metric_fn: 0.4481 - lr: 0.0017\n",
      "Epoch 33/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4440 - val_loss: 0.4486 - val_metric_fn: 0.4482 - lr: 0.0017\n",
      "Epoch 34/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4441 - val_loss: 0.4484 - val_metric_fn: 0.4481 - lr: 0.0012\n",
      "Epoch 35/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4480 - val_metric_fn: 0.4478 - lr: 0.0012\n",
      "Epoch 36/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4440 - val_loss: 0.4480 - val_metric_fn: 0.4478 - lr: 0.0012\n",
      "Epoch 37/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4480 - val_metric_fn: 0.4477 - lr: 0.0012\n",
      "Epoch 38/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4440 - val_loss: 0.4482 - val_metric_fn: 0.4479 - lr: 0.0012\n",
      "Epoch 39/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4440 - val_loss: 0.4481 - val_metric_fn: 0.4478 - lr: 0.0012\n",
      "Epoch 40/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4443 - metric_fn: 0.4439 - val_loss: 0.4480 - val_metric_fn: 0.4477 - lr: 8.4035e-04\n",
      "Epoch 41/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4442 - metric_fn: 0.4438 - val_loss: 0.4485 - val_metric_fn: 0.4482 - lr: 8.4035e-04\n",
      "Epoch 42/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4480 - val_metric_fn: 0.4478 - lr: 8.4035e-04\n",
      "Epoch 43/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4443 - metric_fn: 0.4438 - val_loss: 0.4480 - val_metric_fn: 0.4478 - lr: 8.4035e-04\n",
      "Epoch 44/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4442 - metric_fn: 0.4438 - val_loss: 0.4478 - val_metric_fn: 0.4475 - lr: 5.8825e-04\n",
      "Epoch 45/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4442 - metric_fn: 0.4438 - val_loss: 0.4478 - val_metric_fn: 0.4476 - lr: 5.8825e-04\n",
      "Epoch 46/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4442 - metric_fn: 0.4437 - val_loss: 0.4480 - val_metric_fn: 0.4478 - lr: 5.8825e-04\n",
      "Epoch 47/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4441 - metric_fn: 0.4438 - val_loss: 0.4478 - val_metric_fn: 0.4476 - lr: 5.8825e-04\n",
      "Epoch 48/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4443 - metric_fn: 0.4439 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 5.8825e-04\n",
      "Epoch 49/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4442 - metric_fn: 0.4438 - val_loss: 0.4478 - val_metric_fn: 0.4477 - lr: 4.1177e-04\n",
      "Epoch 50/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4437 - val_loss: 0.4479 - val_metric_fn: 0.4477 - lr: 4.1177e-04\n",
      "Epoch 51/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4478 - val_metric_fn: 0.4476 - lr: 4.1177e-04\n",
      "Epoch 52/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4441 - metric_fn: 0.4437 - val_loss: 0.4479 - val_metric_fn: 0.4477 - lr: 4.1177e-04\n",
      "Epoch 53/177\n",
      "873/873 [==============================] - 3s 3ms/step - loss: 0.4441 - metric_fn: 0.4438 - val_loss: 0.4478 - val_metric_fn: 0.4477 - lr: 2.8824e-04\n",
      "Epoch 54/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.8824e-04\n",
      "Epoch 55/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4441 - metric_fn: 0.4437 - val_loss: 0.4478 - val_metric_fn: 0.4476 - lr: 2.8824e-04\n",
      "Epoch 56/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4437 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.8824e-04\n",
      "Epoch 57/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.0177e-04\n",
      "Epoch 58/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 2.0177e-04\n",
      "Epoch 59/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.0177e-04\n",
      "Epoch 60/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.0177e-04\n",
      "Epoch 61/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 2.0177e-04\n",
      "Epoch 62/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 2.0177e-04\n",
      "Epoch 63/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 1.4124e-04\n",
      "Epoch 64/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.4124e-04\n",
      "Epoch 65/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 1.4124e-04\n",
      "Epoch 66/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.4124e-04\n",
      "Epoch 67/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 9.8866e-05\n",
      "Epoch 68/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4434 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 9.8866e-05\n",
      "Epoch 69/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 9.8866e-05\n",
      "Epoch 70/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 9.8866e-05\n",
      "Epoch 71/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 6.9206e-05\n",
      "Epoch 72/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4433 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 6.9206e-05\n",
      "Epoch 73/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 6.9206e-05\n",
      "Epoch 74/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 6.9206e-05\n",
      "Epoch 75/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 4.8445e-05\n",
      "Epoch 76/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 4.8445e-05\n",
      "Epoch 77/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 4.8445e-05\n",
      "Epoch 78/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4477 - val_metric_fn: 0.4475 - lr: 4.8445e-05\n",
      "Epoch 79/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 3.3911e-05\n",
      "Epoch 80/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 3.3911e-05\n",
      "Epoch 81/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4477 - val_metric_fn: 0.4476 - lr: 3.3911e-05\n",
      "Epoch 82/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 3.3911e-05\n",
      "Epoch 83/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 2.3738e-05\n",
      "Epoch 84/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 2.3738e-05\n",
      "Epoch 85/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 2.3738e-05\n",
      "Epoch 86/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 2.3738e-05\n",
      "Epoch 87/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.6616e-05\n",
      "Epoch 88/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.6616e-05\n",
      "Epoch 89/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.6616e-05\n",
      "Epoch 90/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.6616e-05\n",
      "Epoch 91/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.1632e-05\n",
      "Epoch 92/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.1632e-05\n",
      "Epoch 93/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.1632e-05\n",
      "Epoch 94/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4440 - metric_fn: 0.4437 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.1632e-05\n",
      "Epoch 95/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 96/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 97/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 98/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 99/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 100/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 101/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 102/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 103/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 104/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 105/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 106/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 107/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 108/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 109/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 110/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 111/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 112/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 113/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 114/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 115/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 116/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 117/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 118/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 119/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 120/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 121/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 122/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 123/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 124/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 125/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 126/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 127/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 128/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 129/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 130/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 131/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 132/177\n",
      "873/873 [==============================] - 3s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 133/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 134/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 135/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 136/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 137/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 138/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 139/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 140/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 141/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 142/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 143/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4439 - metric_fn: 0.4436 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 144/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 145/177\n",
      "873/873 [==============================] - 3s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 146/177\n",
      "873/873 [==============================] - 3s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 147/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4437 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 148/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 149/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 150/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 151/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4438 - metric_fn: 0.4435 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 152/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 153/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4434 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 154/177\n",
      "858/873 [============================>.] - ETA: 0s - loss: 0.4440 - metric_fn: 0.4438Restoring model weights from the end of the best epoch: 119.\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4436 - metric_fn: 0.4433 - val_loss: 0.4476 - val_metric_fn: 0.4475 - lr: 1.0000e-05\n",
      "Epoch 154: early stopping\n",
      "343/343 [==============================] - 1s 1ms/step\n",
      "-------------------3-------------------------\n",
      "Epoch 1/177\n",
      "873/873 [==============================] - 4s 3ms/step - loss: 0.4819 - metric_fn: 0.4719 - val_loss: 0.4530 - val_metric_fn: 0.4455 - lr: 0.0050\n",
      "Epoch 2/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4546 - metric_fn: 0.4483 - val_loss: 0.4503 - val_metric_fn: 0.4458 - lr: 0.0050\n",
      "Epoch 3/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4517 - metric_fn: 0.4477 - val_loss: 0.4466 - val_metric_fn: 0.4435 - lr: 0.0050\n",
      "Epoch 4/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4501 - metric_fn: 0.4471 - val_loss: 0.4460 - val_metric_fn: 0.4435 - lr: 0.0050\n",
      "Epoch 5/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4496 - metric_fn: 0.4471 - val_loss: 0.4456 - val_metric_fn: 0.4435 - lr: 0.0050\n",
      "Epoch 6/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4491 - metric_fn: 0.4470 - val_loss: 0.4448 - val_metric_fn: 0.4430 - lr: 0.0050\n",
      "Epoch 7/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4484 - metric_fn: 0.4466 - val_loss: 0.4442 - val_metric_fn: 0.4427 - lr: 0.0050\n",
      "Epoch 8/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4484 - metric_fn: 0.4468 - val_loss: 0.4451 - val_metric_fn: 0.4440 - lr: 0.0050\n",
      "Epoch 9/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4482 - metric_fn: 0.4468 - val_loss: 0.4439 - val_metric_fn: 0.4428 - lr: 0.0050\n",
      "Epoch 10/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4482 - metric_fn: 0.4468 - val_loss: 0.4439 - val_metric_fn: 0.4429 - lr: 0.0050\n",
      "Epoch 11/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4479 - metric_fn: 0.4467 - val_loss: 0.4444 - val_metric_fn: 0.4435 - lr: 0.0050\n",
      "Epoch 12/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4476 - metric_fn: 0.4465 - val_loss: 0.4439 - val_metric_fn: 0.4432 - lr: 0.0050\n",
      "Epoch 13/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4476 - metric_fn: 0.4465 - val_loss: 0.4432 - val_metric_fn: 0.4426 - lr: 0.0050\n",
      "Epoch 14/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4473 - metric_fn: 0.4463 - val_loss: 0.4439 - val_metric_fn: 0.4433 - lr: 0.0050\n",
      "Epoch 15/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4473 - metric_fn: 0.4463 - val_loss: 0.4438 - val_metric_fn: 0.4431 - lr: 0.0050\n",
      "Epoch 16/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4474 - metric_fn: 0.4464 - val_loss: 0.4436 - val_metric_fn: 0.4429 - lr: 0.0050\n",
      "Epoch 17/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4474 - metric_fn: 0.4464 - val_loss: 0.4434 - val_metric_fn: 0.4428 - lr: 0.0050\n",
      "Epoch 18/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4461 - val_loss: 0.4431 - val_metric_fn: 0.4426 - lr: 0.0035\n",
      "Epoch 19/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4460 - val_loss: 0.4430 - val_metric_fn: 0.4426 - lr: 0.0035\n",
      "Epoch 20/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4461 - val_loss: 0.4443 - val_metric_fn: 0.4439 - lr: 0.0035\n",
      "Epoch 21/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4467 - metric_fn: 0.4459 - val_loss: 0.4440 - val_metric_fn: 0.4435 - lr: 0.0035\n",
      "Epoch 22/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4461 - val_loss: 0.4430 - val_metric_fn: 0.4425 - lr: 0.0035\n",
      "Epoch 23/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4465 - metric_fn: 0.4458 - val_loss: 0.4429 - val_metric_fn: 0.4424 - lr: 0.0025\n",
      "Epoch 24/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4457 - val_loss: 0.4426 - val_metric_fn: 0.4422 - lr: 0.0025\n",
      "Epoch 25/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4466 - metric_fn: 0.4458 - val_loss: 0.4430 - val_metric_fn: 0.4425 - lr: 0.0025\n",
      "Epoch 26/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4457 - val_loss: 0.4433 - val_metric_fn: 0.4429 - lr: 0.0025\n",
      "Epoch 27/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4465 - metric_fn: 0.4458 - val_loss: 0.4430 - val_metric_fn: 0.4425 - lr: 0.0025\n",
      "Epoch 28/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4457 - val_loss: 0.4431 - val_metric_fn: 0.4427 - lr: 0.0025\n",
      "Epoch 29/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4455 - val_loss: 0.4425 - val_metric_fn: 0.4422 - lr: 0.0017\n",
      "Epoch 30/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4454 - val_loss: 0.4428 - val_metric_fn: 0.4425 - lr: 0.0017\n",
      "Epoch 31/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4455 - val_loss: 0.4427 - val_metric_fn: 0.4424 - lr: 0.0017\n",
      "Epoch 32/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4462 - metric_fn: 0.4456 - val_loss: 0.4426 - val_metric_fn: 0.4423 - lr: 0.0017\n",
      "Epoch 33/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4454 - val_loss: 0.4425 - val_metric_fn: 0.4422 - lr: 0.0012\n",
      "Epoch 34/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4454 - val_loss: 0.4425 - val_metric_fn: 0.4422 - lr: 0.0012\n",
      "Epoch 35/177\n",
      "873/873 [==============================] - 3s 3ms/step - loss: 0.4461 - metric_fn: 0.4455 - val_loss: 0.4422 - val_metric_fn: 0.4419 - lr: 0.0012\n",
      "Epoch 36/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4453 - val_loss: 0.4424 - val_metric_fn: 0.4421 - lr: 0.0012\n",
      "Epoch 37/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4454 - val_loss: 0.4425 - val_metric_fn: 0.4422 - lr: 0.0012\n",
      "Epoch 38/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4453 - val_loss: 0.4423 - val_metric_fn: 0.4421 - lr: 0.0012\n",
      "Epoch 39/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4454 - val_loss: 0.4425 - val_metric_fn: 0.4423 - lr: 0.0012\n",
      "Epoch 40/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4451 - val_loss: 0.4422 - val_metric_fn: 0.4420 - lr: 8.4035e-04\n",
      "Epoch 41/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4452 - val_loss: 0.4427 - val_metric_fn: 0.4425 - lr: 8.4035e-04\n",
      "Epoch 42/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4452 - val_loss: 0.4423 - val_metric_fn: 0.4421 - lr: 8.4035e-04\n",
      "Epoch 43/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4453 - val_loss: 0.4421 - val_metric_fn: 0.4419 - lr: 8.4035e-04\n",
      "Epoch 44/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4451 - val_loss: 0.4421 - val_metric_fn: 0.4419 - lr: 5.8825e-04\n",
      "Epoch 45/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4452 - val_loss: 0.4420 - val_metric_fn: 0.4418 - lr: 5.8825e-04\n",
      "Epoch 46/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4452 - val_loss: 0.4421 - val_metric_fn: 0.4419 - lr: 5.8825e-04\n",
      "Epoch 47/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4452 - val_loss: 0.4422 - val_metric_fn: 0.4420 - lr: 5.8825e-04\n",
      "Epoch 48/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4421 - val_metric_fn: 0.4419 - lr: 5.8825e-04\n",
      "Epoch 49/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4451 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 4.1177e-04\n",
      "Epoch 50/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4419 - lr: 4.1177e-04\n",
      "Epoch 51/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4422 - val_metric_fn: 0.4421 - lr: 4.1177e-04\n",
      "Epoch 52/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 4.1177e-04\n",
      "Epoch 53/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 2.8824e-04\n",
      "Epoch 54/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4449 - val_loss: 0.4423 - val_metric_fn: 0.4421 - lr: 2.8824e-04\n",
      "Epoch 55/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 2.8824e-04\n",
      "Epoch 56/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4449 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 2.8824e-04\n",
      "Epoch 57/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 2.0177e-04\n",
      "Epoch 58/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4451 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 2.0177e-04\n",
      "Epoch 59/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 2.0177e-04\n",
      "Epoch 60/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4449 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 2.0177e-04\n",
      "Epoch 61/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 2.0177e-04\n",
      "Epoch 62/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 2.0177e-04\n",
      "Epoch 63/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4420 - val_metric_fn: 0.4419 - lr: 2.0177e-04\n",
      "Epoch 64/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 1.4124e-04\n",
      "Epoch 65/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 1.4124e-04\n",
      "Epoch 66/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 1.4124e-04\n",
      "Epoch 67/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4450 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 1.4124e-04\n",
      "Epoch 68/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 9.8866e-05\n",
      "Epoch 69/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 9.8866e-05\n",
      "Epoch 70/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 9.8866e-05\n",
      "Epoch 71/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 9.8866e-05\n",
      "Epoch 72/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 6.9206e-05\n",
      "Epoch 73/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 6.9206e-05\n",
      "Epoch 74/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 6.9206e-05\n",
      "Epoch 75/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 6.9206e-05\n",
      "Epoch 76/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 4.8445e-05\n",
      "Epoch 77/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 4.8445e-05\n",
      "Epoch 78/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 4.8445e-05\n",
      "Epoch 79/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 4.8445e-05\n",
      "Epoch 80/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4421 - val_metric_fn: 0.4420 - lr: 3.3911e-05\n",
      "Epoch 81/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 3.3911e-05\n",
      "Epoch 82/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 3.3911e-05\n",
      "Epoch 83/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 3.3911e-05\n",
      "Epoch 84/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 2.3738e-05\n",
      "Epoch 85/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4450 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 2.3738e-05\n",
      "Epoch 86/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 2.3738e-05\n",
      "Epoch 87/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4447 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 2.3738e-05\n",
      "Epoch 88/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.6616e-05\n",
      "Epoch 89/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.6616e-05\n",
      "Epoch 90/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.6616e-05\n",
      "Epoch 91/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4447 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.6616e-05\n",
      "Epoch 92/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4449 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.1632e-05\n",
      "Epoch 93/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.1632e-05\n",
      "Epoch 94/177\n",
      "873/873 [==============================] - ETA: 0s - loss: 0.4451 - metric_fn: 0.4448Restoring model weights from the end of the best epoch: 59.\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4448 - val_loss: 0.4420 - val_metric_fn: 0.4420 - lr: 1.1632e-05\n",
      "Epoch 94: early stopping\n",
      "343/343 [==============================] - 1s 1ms/step\n",
      "-------------------4-------------------------\n",
      "Epoch 1/177\n",
      "873/873 [==============================] - 4s 3ms/step - loss: 0.4820 - metric_fn: 0.4722 - val_loss: 0.4548 - val_metric_fn: 0.4473 - lr: 0.0050\n",
      "Epoch 2/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4540 - metric_fn: 0.4478 - val_loss: 0.4512 - val_metric_fn: 0.4464 - lr: 0.0050\n",
      "Epoch 3/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4509 - metric_fn: 0.4468 - val_loss: 0.4486 - val_metric_fn: 0.4453 - lr: 0.0050\n",
      "Epoch 4/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4495 - metric_fn: 0.4464 - val_loss: 0.4483 - val_metric_fn: 0.4457 - lr: 0.0050\n",
      "Epoch 5/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4488 - metric_fn: 0.4463 - val_loss: 0.4486 - val_metric_fn: 0.4465 - lr: 0.0050\n",
      "Epoch 6/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4484 - metric_fn: 0.4463 - val_loss: 0.4473 - val_metric_fn: 0.4455 - lr: 0.0050\n",
      "Epoch 7/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4480 - metric_fn: 0.4462 - val_loss: 0.4482 - val_metric_fn: 0.4466 - lr: 0.0050\n",
      "Epoch 8/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4478 - metric_fn: 0.4463 - val_loss: 0.4486 - val_metric_fn: 0.4473 - lr: 0.0050\n",
      "Epoch 9/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4474 - metric_fn: 0.4461 - val_loss: 0.4470 - val_metric_fn: 0.4458 - lr: 0.0050\n",
      "Epoch 10/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4473 - metric_fn: 0.4461 - val_loss: 0.4491 - val_metric_fn: 0.4480 - lr: 0.0050\n",
      "Epoch 11/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4472 - metric_fn: 0.4460 - val_loss: 0.4470 - val_metric_fn: 0.4461 - lr: 0.0050\n",
      "Epoch 12/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4472 - metric_fn: 0.4462 - val_loss: 0.4463 - val_metric_fn: 0.4454 - lr: 0.0050\n",
      "Epoch 13/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4471 - metric_fn: 0.4459 - val_loss: 0.4458 - val_metric_fn: 0.4449 - lr: 0.0050\n",
      "Epoch 14/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4470 - metric_fn: 0.4460 - val_loss: 0.4461 - val_metric_fn: 0.4452 - lr: 0.0050\n",
      "Epoch 15/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4468 - metric_fn: 0.4458 - val_loss: 0.4461 - val_metric_fn: 0.4452 - lr: 0.0050\n",
      "Epoch 16/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4458 - val_loss: 0.4461 - val_metric_fn: 0.4451 - lr: 0.0050\n",
      "Epoch 17/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4469 - metric_fn: 0.4459 - val_loss: 0.4461 - val_metric_fn: 0.4452 - lr: 0.0050\n",
      "Epoch 18/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4454 - val_loss: 0.4458 - val_metric_fn: 0.4450 - lr: 0.0035\n",
      "Epoch 19/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4465 - metric_fn: 0.4456 - val_loss: 0.4467 - val_metric_fn: 0.4459 - lr: 0.0035\n",
      "Epoch 20/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4459 - val_metric_fn: 0.4452 - lr: 0.0035\n",
      "Epoch 21/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4456 - val_metric_fn: 0.4449 - lr: 0.0035\n",
      "Epoch 22/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4458 - val_metric_fn: 0.4451 - lr: 0.0035\n",
      "Epoch 23/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4461 - val_metric_fn: 0.4454 - lr: 0.0035\n",
      "Epoch 24/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4463 - metric_fn: 0.4455 - val_loss: 0.4458 - val_metric_fn: 0.4450 - lr: 0.0035\n",
      "Epoch 25/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4464 - metric_fn: 0.4455 - val_loss: 0.4460 - val_metric_fn: 0.4453 - lr: 0.0035\n",
      "Epoch 26/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4461 - metric_fn: 0.4453 - val_loss: 0.4459 - val_metric_fn: 0.4452 - lr: 0.0025\n",
      "Epoch 27/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4451 - val_loss: 0.4454 - val_metric_fn: 0.4448 - lr: 0.0025\n",
      "Epoch 28/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4451 - val_loss: 0.4456 - val_metric_fn: 0.4451 - lr: 0.0025\n",
      "Epoch 29/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4452 - val_loss: 0.4458 - val_metric_fn: 0.4453 - lr: 0.0025\n",
      "Epoch 30/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4459 - metric_fn: 0.4451 - val_loss: 0.4465 - val_metric_fn: 0.4460 - lr: 0.0025\n",
      "Epoch 31/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4460 - metric_fn: 0.4453 - val_loss: 0.4455 - val_metric_fn: 0.4449 - lr: 0.0025\n",
      "Epoch 32/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4449 - val_loss: 0.4453 - val_metric_fn: 0.4448 - lr: 0.0017\n",
      "Epoch 33/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4450 - val_loss: 0.4450 - val_metric_fn: 0.4444 - lr: 0.0017\n",
      "Epoch 34/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4456 - metric_fn: 0.4450 - val_loss: 0.4455 - val_metric_fn: 0.4450 - lr: 0.0017\n",
      "Epoch 35/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4458 - metric_fn: 0.4451 - val_loss: 0.4453 - val_metric_fn: 0.4448 - lr: 0.0017\n",
      "Epoch 36/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4457 - metric_fn: 0.4450 - val_loss: 0.4452 - val_metric_fn: 0.4447 - lr: 0.0017\n",
      "Epoch 37/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4449 - val_loss: 0.4450 - val_metric_fn: 0.4445 - lr: 0.0017\n",
      "Epoch 38/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4448 - val_loss: 0.4449 - val_metric_fn: 0.4445 - lr: 0.0012\n",
      "Epoch 39/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4454 - metric_fn: 0.4448 - val_loss: 0.4452 - val_metric_fn: 0.4447 - lr: 0.0012\n",
      "Epoch 40/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4447 - val_loss: 0.4451 - val_metric_fn: 0.4446 - lr: 0.0012\n",
      "Epoch 41/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4455 - metric_fn: 0.4449 - val_loss: 0.4453 - val_metric_fn: 0.4449 - lr: 0.0012\n",
      "Epoch 42/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4447 - val_loss: 0.4452 - val_metric_fn: 0.4448 - lr: 8.4035e-04\n",
      "Epoch 43/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4447 - val_loss: 0.4452 - val_metric_fn: 0.4448 - lr: 8.4035e-04\n",
      "Epoch 44/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4447 - val_loss: 0.4454 - val_metric_fn: 0.4449 - lr: 8.4035e-04\n",
      "Epoch 45/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4453 - metric_fn: 0.4448 - val_loss: 0.4449 - val_metric_fn: 0.4445 - lr: 8.4035e-04\n",
      "Epoch 46/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4449 - val_metric_fn: 0.4444 - lr: 5.8825e-04\n",
      "Epoch 47/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4445 - val_loss: 0.4449 - val_metric_fn: 0.4445 - lr: 5.8825e-04\n",
      "Epoch 48/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4445 - val_loss: 0.4448 - val_metric_fn: 0.4444 - lr: 5.8825e-04\n",
      "Epoch 49/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4447 - val_loss: 0.4448 - val_metric_fn: 0.4444 - lr: 5.8825e-04\n",
      "Epoch 50/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4451 - metric_fn: 0.4446 - val_loss: 0.4452 - val_metric_fn: 0.4448 - lr: 5.8825e-04\n",
      "Epoch 51/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4450 - val_metric_fn: 0.4447 - lr: 5.8825e-04\n",
      "Epoch 52/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4452 - metric_fn: 0.4448 - val_loss: 0.4449 - val_metric_fn: 0.4446 - lr: 5.8825e-04\n",
      "Epoch 53/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4447 - val_metric_fn: 0.4443 - lr: 4.1177e-04\n",
      "Epoch 54/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4451 - val_metric_fn: 0.4447 - lr: 4.1177e-04\n",
      "Epoch 55/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4448 - val_metric_fn: 0.4444 - lr: 4.1177e-04\n",
      "Epoch 56/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4446 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 4.1177e-04\n",
      "Epoch 57/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4450 - metric_fn: 0.4445 - val_loss: 0.4448 - val_metric_fn: 0.4445 - lr: 4.1177e-04\n",
      "Epoch 58/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4444 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 2.8824e-04\n",
      "Epoch 59/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4444 - val_loss: 0.4448 - val_metric_fn: 0.4445 - lr: 2.8824e-04\n",
      "Epoch 60/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4443 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 2.8824e-04\n",
      "Epoch 61/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4443 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 2.8824e-04\n",
      "Epoch 62/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4444 - val_loss: 0.4447 - val_metric_fn: 0.4445 - lr: 2.0177e-04\n",
      "Epoch 63/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4441 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 2.0177e-04\n",
      "Epoch 64/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4444 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 2.0177e-04\n",
      "Epoch 65/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4443 - val_loss: 0.4449 - val_metric_fn: 0.4446 - lr: 2.0177e-04\n",
      "Epoch 66/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4444 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 1.4124e-04\n",
      "Epoch 67/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4444 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.4124e-04\n",
      "Epoch 68/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.4124e-04\n",
      "Epoch 69/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 1.4124e-04\n",
      "Epoch 70/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4449 - metric_fn: 0.4445 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 9.8866e-05\n",
      "Epoch 71/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 9.8866e-05\n",
      "Epoch 72/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 9.8866e-05\n",
      "Epoch 73/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4448 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 9.8866e-05\n",
      "Epoch 74/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 9.8866e-05\n",
      "Epoch 75/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 9.8866e-05\n",
      "Epoch 76/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 9.8866e-05\n",
      "Epoch 77/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 6.9206e-05\n",
      "Epoch 78/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4447 - val_metric_fn: 0.4444 - lr: 6.9206e-05\n",
      "Epoch 79/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 6.9206e-05\n",
      "Epoch 80/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 6.9206e-05\n",
      "Epoch 81/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 4.8445e-05\n",
      "Epoch 82/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 4.8445e-05\n",
      "Epoch 83/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 4.8445e-05\n",
      "Epoch 84/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 4.8445e-05\n",
      "Epoch 85/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 3.3911e-05\n",
      "Epoch 86/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 3.3911e-05\n",
      "Epoch 87/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 3.3911e-05\n",
      "Epoch 88/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 3.3911e-05\n",
      "Epoch 89/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 2.3738e-05\n",
      "Epoch 90/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 2.3738e-05\n",
      "Epoch 91/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 2.3738e-05\n",
      "Epoch 92/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 2.3738e-05\n",
      "Epoch 93/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.6616e-05\n",
      "Epoch 94/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.6616e-05\n",
      "Epoch 95/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.6616e-05\n",
      "Epoch 96/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.6616e-05\n",
      "Epoch 97/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.1632e-05\n",
      "Epoch 98/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.1632e-05\n",
      "Epoch 99/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.1632e-05\n",
      "Epoch 100/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.1632e-05\n",
      "Epoch 101/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 102/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 103/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 104/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 105/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 106/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 107/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 108/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 109/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 110/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 111/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 112/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 113/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 114/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 115/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 116/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 117/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 118/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 119/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 120/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 121/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4444 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 122/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 123/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 124/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 125/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 126/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 127/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 128/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 129/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 130/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 131/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 132/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 133/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 134/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 135/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 136/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 137/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 138/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 139/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 140/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 141/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 142/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4440 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 143/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 144/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 145/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 146/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 147/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4447 - metric_fn: 0.4443 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 148/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 149/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4443 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 150/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4444 - metric_fn: 0.4441 - val_loss: 0.4445 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 151/177\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4446 - metric_fn: 0.4442 - val_loss: 0.4446 - val_metric_fn: 0.4443 - lr: 1.0000e-05\n",
      "Epoch 152/177\n",
      "867/873 [============================>.] - ETA: 0s - loss: 0.4444 - metric_fn: 0.4441Restoring model weights from the end of the best epoch: 117.\n",
      "873/873 [==============================] - 2s 3ms/step - loss: 0.4445 - metric_fn: 0.4441 - val_loss: 0.4446 - val_metric_fn: 0.4444 - lr: 1.0000e-05\n",
      "Epoch 152: early stopping\n",
      "343/343 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_histories = []\n",
    "test_preds = np.zeros(len(test_x))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(train_x, train_y)):\n",
    "    print(f'-------------------{ i }-------------------------')\n",
    "    # print(train_index)\n",
    "    x_train_fold, x_valid_fold = train_x.iloc[train_index], train_x.iloc[valid_index]\n",
    "    y_train_fold, y_valid_fold = train_y.iloc[train_index], train_y.iloc[valid_index]\n",
    "    # print(x_train_fold.shape, x_valid_fold.shape, y_train_fold.shape,y_valid_fold.shape)\n",
    "    \n",
    "    optimized_model = create_model(best_params['l1_reg'], best_params['l2_reg'], best_params['learning_rate'])\n",
    "    history = optimized_model.fit(\n",
    "                            x_train_fold.astype('float32'), y_train_fold.astype('float32'),\n",
    "                            epochs=177, batch_size=best_params['batch_size'], verbose=1,\n",
    "                            validation_data=(x_valid_fold.astype('float32'), y_valid_fold.astype('float32')),\n",
    "                            callbacks=callbacks_list)\n",
    "    \n",
    "    fold_histories.append(history)\n",
    "    \n",
    "    test_preds +=  optimized_model.predict(test_x.astype('float32')).reshape(-1) / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train loss, val loss 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.182757\n",
       "1        3.770513\n",
       "2        5.041654\n",
       "3        4.232349\n",
       "4        4.687727\n",
       "           ...   \n",
       "10958    5.433143\n",
       "10959    4.408441\n",
       "10960    4.908741\n",
       "10961    4.649559\n",
       "10962    4.494154\n",
       "Name: ECLO, Length: 10963, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "sample_submission[\"ECLO\"] = test_preds\n",
    "\n",
    "sample_submission.to_csv(\"result/kf5_BN_submission.csv\", index=False)\n",
    "sample_submission[\"ECLO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daegu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
